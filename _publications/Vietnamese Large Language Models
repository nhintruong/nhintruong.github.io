---
title: "Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models"
collection: publications
# permalink: /publication/ura-llama
excerpt: 'Recent advancements in large language models (LLMs) have underscored their importance in the evolution of artificial intelligence. However, despite extensive pretrained on multilingual datasets, available open-sourced LLMs exhibit limited effectiveness in processing Vietnamese. The challenge is exacerbated by the absence of systematic benchmark datasets and metrics tailored for Vietnamese LLM evaluation. To mitigate these issues, we have finetuned LLMs specifically for Vietnamese and developed a comprehensive evaluation framework encompassing 10 common tasks and 31 metrics. Our evaluation results reveal that the fine-tuned LLMs exhibit enhanced comprehension and generative capabilities in Vietnamese. Moreover, our analysis indicates that models with more parameters can introduce more biases and uncalibrated outputs and the key factor influencing LLM performance is the quality of the training or fine-tuning datasets. These insights underscore the significance of meticulous fine-tuning with high-quality datasets in enhancing LLM performance.'
date: 2024-03-13
venue: 'NAACL'
paperurl: 'https://drive.google.com/file/d/1t-rn-MR9B1NkxwhPA3NcUXe5TRSBAAWi/view?usp=sharing'
---

This research addresses the limited capabilities of existing large language models in processing Vietnamese, a language spoken by over 100 million people. We developed and released five open-source Vietnamese language models by adapting well-known models like LLaMa-2, Mixtral, and Gemma through specialized training on Vietnamese text from Wikipedia, news articles, and student essays. To properly assess these models, we created a comprehensive evaluation framework covering ten practical use casesâ€”from question-answering and summarization to detecting toxic content and logical reasoning. Our evaluation of 14 different models revealed several important insights: training data quality matters more than model size alone, and while larger models can be more powerful, they can also exhibit more biases and be harder to control. We also found that models can effectively transfer knowledge across languages, making targeted training an efficient approach for improving performance in lower-resource languages. All our models and evaluation tools are publicly available to support further research and development in Vietnamese language technology. 

<br>
<br>

<p><strong>Press & Recognition:</strong> Featured in <a href="https://www.nytimes.com/2024/07/26/technology/ai-language-gap.html">The New York Times</a> and <a href="https://hai.stanford.edu/news/improving-equity-and-access-non-english-large-language-models">Stanford HAI</a>.</p>